{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRFj8BSOWxmt",
        "outputId": "8fee5dcb-3f37-4efc-fd3b-79c51bbc8344"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words_eng = stopwords.words(\"english\")\n",
        "stop_words_ger = stopwords.words(\"german\")\n",
        "import warnings\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YsQhic9Q21Hn",
        "outputId": "1477fb84-85c2-4a29-db2c-5e8c5a4e606b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "mount failed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-590f66334c11>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl_eng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'/content/drive/MyDrive/TextSent/training set.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0murl_eng_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'/content/drive/MyDrive/TextSent/testing set.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "url_eng = r'/content/drive/MyDrive/TextSent/training set.csv'\n",
        "url_eng_test = r'/content/drive/MyDrive/TextSent/testing set.csv'\n",
        "url_ger = r'/content/drive/MyDrive/TextSent/RP-Mod-Crowd.csv'\n",
        "\n",
        "\n",
        "df_eng = pd.read_csv(url_eng)\n",
        "df_eng_test = pd.read_csv(url_eng_test)\n",
        "df_ger = pd.read_csv(url_ger, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mukvJyvCv7WB"
      },
      "outputs": [],
      "source": [
        "df_eng = df_eng._append(df_eng_test,ignore_index=True)\n",
        "df_eng.dropna()\n",
        "\n",
        "df_eng['racist'] = df_eng['categories'] #add new column\n",
        "df_eng['sexist'] = df_eng['categories'] #add new column\n",
        "\n",
        "df_eng = df_eng.rename(columns={ 'tweet':'text'})\n",
        "df_eng['racist'] = df_eng['racist'].replace('Race', 1).apply(lambda x: 0 if x != 1 else x)\n",
        "df_eng['sexist'] = df_eng['sexist'].replace({'Gender'}, 1).apply(lambda x: 0 if x != 1 else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4wK0x073rdK"
      },
      "outputs": [],
      "source": [
        "df_ger.dropna()\n",
        "df_ger = df_ger[['Text','Reject Newspaper', 'Sexism Count Crowd', 'Racism Count Crowd']]\n",
        "df_ger = df_ger.rename(columns={'Sexism Count Crowd':'sexist','Racism Count Crowd':'racist','Text':'text'})\n",
        "df_ger['racist'] = df_ger['racist'].apply(lambda x: 1 if x > 1 else 0)\n",
        "df_ger['sexist'] = df_ger['sexist'].apply(lambda x: 1 if x > 1 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYJ9Idccb_OI"
      },
      "outputs": [],
      "source": [
        "df_ger.text=df_ger.text.astype(str)\n",
        "df_ger = df_ger[df_ger['text'].map(len) < 200]\n",
        "df_ger = df_ger[df_ger['text'].map(len) > 30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQWqCDckOdeA",
        "outputId": "10aa4f34-15cf-4b12-c04b-2062a6346227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m41.0/42.3 kB\u001b[0m \u001b[31m941.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m766.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.2.2)\n",
            "Installing collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n"
          ]
        }
      ],
      "source": [
        "pip install deep-translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkzxwbDALoNv"
      },
      "outputs": [],
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "df = df_ger\n",
        "\n",
        "list_of_languages = [\"it\", \"es\", \"fr\", \"en\", \"pt\"]\n",
        "df_augmented_full = df.copy()\n",
        "\n",
        "def data_augmentation(text, translation_language):\n",
        "\n",
        "  text = GoogleTranslator(source=\"de\", target=translation_language).translate(text)\n",
        "  de_text = GoogleTranslator(source=translation_language, target=\"de\").translate(text)\n",
        "  return de_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTDl7N1nC-Lm"
      },
      "outputs": [],
      "source": [
        "for language in list_of_languages:\n",
        "\n",
        "      augmented_list_sexist = df[df.sexist == True].text.apply(lambda x: data_augmentation(x, language))\n",
        "\n",
        "      cols = [\"text\", \"sexist\"]\n",
        "      df_augmented_language = pd.DataFrame(augmented_list_sexist, columns=cols)\n",
        "      df_augmented_language[\"sexist\"] = 1\n",
        "\n",
        "      df_augmented_full = pd.concat([df_augmented_full, df_augmented_language], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEsZydthC_sE"
      },
      "outputs": [],
      "source": [
        "df_r = df[df.racist == True]\n",
        "for language in list_of_languages:\n",
        "\n",
        "      augmented_list_racist = df_r.text.apply(lambda x: data_augmentation(x, language))\n",
        "\n",
        "      cols = [\"text\", \"racist\"]\n",
        "      df_augmented_language_racist = pd.DataFrame(augmented_list_racist, columns=cols)\n",
        "      df_augmented_language_racist[\"racist\"] = 1\n",
        "\n",
        "      df_augmented_full = pd.concat([df_augmented_full, df_augmented_language_racist], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YrbkUdrLUhd"
      },
      "outputs": [],
      "source": [
        "df_eng_pp = preprocess_dataframe_eng(df_eng)\n",
        "df_eng_pp.text=df_eng.text.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1FTH0cgBIuA"
      },
      "outputs": [],
      "source": [
        "# Export\n",
        "df_augmented_full.to_csv('/content/drive/MyDrive/TextSent/augmented_german_data.csv', index=False)\n",
        "df_eng_pp.to_csv('/content/drive/MyDrive/TextSent/df_eng_pp.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKtyXzTmTnouKjHGiXSEfI"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}